---
title: "Customer Data Analysis"
output: html_notebook
---

We want to analyze our customer data, and better understand them.  Please identify:

```{r setup}
load('exerciseData.rda')
```
* The top 10 email_cols by active enterprise users
```{r}
library(dplyr)

# many to many

combine_email_and_tenant_data <- function(relation, emails, tenants, email_col_num, tenant_col_num){
    # save the column names for later
    old_email_name <- colnames(emails)[email_col_num]
    old_tenant_name <- colnames(tenants)[tenant_col_num]
    
    # rename the columns for ease of reference
    colnames(emails)[email_col_num] <- "email_col"
    colnames(tenants)[tenant_col_num] <- "tenant_col"
    
    # create a joined table of tenants and emails
    email_tenant <- left_join(relation, tenants, by='tenant_id') %>%
        left_join(., emails, by='email_id') %>%
        select(tenant_id, email_col, tenant_col) #%>%
    
    # remove non-zero tenant_col, sort by tenant_col and then tenant id, and remove NULL rows
    email_tenant <- email_tenant[email_tenant$tenant_col > 0,]
    email_tenant <- arrange(email_tenant,desc(tenant_col), tenant_id)
    email_tenant <- email_tenant[complete.cases(email_tenant), ]
    
    # get a count of unique tenants and create an empty matrix to hold the deduped data
    unique_tenants <- unique(email_tenant$tenant_id)
    result <- matrix(NA, nrow=length(unique_tenants), ncol=2, dimnames=list(NULL, c("email_col", "tenant_col")))
    
    # create temporary vectors to loop through, as well as placeholder looping variables
    tenant_ids <- data.matrix(email_tenant$tenant_id, rownames.force = NA)
    email_cols <- data.matrix(email_tenant$email_col, rownames.force = NA)
    tenant_cols <- data.matrix(email_tenant$tenant_col, rownames.force = NA)
    temp_email_cols <- email_cols[1]
    temp_tenant_col <- tenant_cols[1]
    index <- 1
    
    # for a given tenant, make a list of all associated email_cols, find the mode,
    # and attribute those tenant_cols to that email_col.  I chose to use this method of 
    # deduping because there is no way to do a proportional attribution for a list of values.
    # Instead of trying to assign fractional portions of value from the tenant_col, it was 
    # less misleading to simply assing them all to the most common email_col value for that tenant
    for (i in 2:length(tenant_ids)){
        if (tenant_ids[i] != tenant_ids[i-1]){
            # get the most frequent email_col from temp list AKA temp_email_cols.mode()
            # TODO: create tiebreaker method
            most_freq_email_col <- names(sort(summary(as.factor(temp_email_cols)), decreasing=T)[1])
            # add it to the matrix
            result[index, 1] <- most_freq_email_col
            # add tenant_col to the matrix
            result[index, 2] <- temp_tenant_col
            # advance index
            index <- index + 1
            # set list of email_cols for next tenant and set temp tenant_col
            temp_email_cols <- email_cols[i]
            temp_tenant_col <- tenant_cols[i]
        } else {
            # add email_col to list of email_cols for a given tenant
            temp_email_cols <- append(temp_email_cols, email_cols[i])
        }
    }
    # remove null rows
    result <- result[complete.cases(result), ]
    result <- as.data.frame(result)
    
    # convert to numeric values and group by email_col, then sort by tenant_col
    result$tenant_col <- as.numeric(as.character(result$tenant_col))
    result <- group_by(result, email_col) %>%
        summarise(tenant_col = sum(tenant_col)) %>%
        arrange(desc(tenant_col))
    
    colnames(result)[1] <- old_email_name
    colnames(result)[2] <- old_tenant_name
    return(result)
}
# dataset_emails$country = 3
# dataset_tenants$active_enterprise_users_last_30d = 6
country_activeusers <- combine_email_and_tenant_data(dataset_relation, dataset_emails, dataset_tenants, 3, 6)
head(country_activeusers, n = 10)
```
* The top 10 operating systems by open and total tickets
```{r}
#many to many

# use function from previous exercise
# dataset_emails$sperating_system = 8
# dataset_tenants$account_open_tickets = 12
operatingsystem_opentickets <- combine_email_and_tenant_data(dataset_relation, dataset_emails, dataset_tenants, 8, 12)
head(operatingsystem_opentickets, n = 10)

# dataset_emails$sperating_system = 8
# dataset_tenants$account_total_tickets = 13
operatingsystem_totaltickets <- combine_email_and_tenant_data(dataset_relation, dataset_emails, dataset_tenants, 8, 13)
head(operatingsystem_totaltickets, n = 10)

```
* The distribution of pageviews per group
```{r}
library(dplyr)
#one to many

pageviews_by_metric <- function(pageviews, emails, email_col_num){
    # save the column names for later
    old_email_name <- colnames(emails)[email_col_num]
    
    # rename the columns for ease of reference
    colnames(emails)[email_col_num] <- "email_col"
    
    # join tables, select and group columns and sum the number of pageviews
    group_pageview <- left_join(pageviews, emails, by='email_id') %>%
        select(email_id, visits, email_col) %>%
        group_by(email_col) %>%
        summarise(total_pageviews = sum(visits))
    
    # order descending by pageviews
    group_pageview <- arrange(group_pageview, -total_pageviews)
    
    # rename column back to old name
    colnames(group_pageview)[1] <- old_email_name
    
    return(group_pageview)
}

# dataset_emails$source_group = 7
output <- pageviews_by_metric(dataset_pageviews, dataset_emails, 7)
output
top_results <- head(output, n = 8)
pie(top_results$total_pageviews, top_results$source_group, main="Pageviews by Source Group")
```
* The distribution differences on pageviews per login method
```{r}
library(dplyr)
#one to many

# use function from previous exercise
# dataset_emails$login_method = 11
output <- pageviews_by_metric(dataset_pageviews, dataset_emails, 11)
output
top_results <- head(output, n = 5)
pie(top_results$total_pageviews, top_results$login_method, main="Pageviews by Login Methods")
```
* What differences do you find between developers and non-developers?
    + There are far more developers than non -- over 11 times as many
    + Company sizes are faily similarly distributed between devs and non-devs in terms of mean and standard deviation
    + Most other metrics are also similarly distributed (e.g., country, source_group, browser).  However the operating systems for devopers put Mac OS X in a slight lead with Windows 10 right behind and Windows 7 trailing.  However, for non-developers, Windows 10 has a dominant lead by almost 40% over Mac OS X, with Windows 7 in a close third place.
    + Even though developer roles outnumber non-devs 11:1, they account for over 16 times as many pageviews as non-devs
    + Developers account for over 36 times as many active users in the last 30 days as non-devs
```{r}
library(dplyr)

# select only rows that are developers or non
devs <- dataset_emails[dataset_emails$role == "developer",]
non_devs <- dataset_emails[dataset_emails$role == "non-developer",]

# calcualte total number of devs/non-devs
print(c("num (devs):", nrow(devs)))
print(c("num (non-devs):", nrow(non_devs)))

# calculate mean and sttdev of company size for each role type
dev_employees <- devs[complete.cases(devs$company_employees), ]$company_employees
non_dev_employees <- non_devs[complete.cases(non_devs$company_employees), ]$company_employees
print(c("mean company size (dev):", mean(dev_employees)))
print(c("mean company size (non-devs):", mean(non_dev_employees)))
print(c("stddev company size (dev):", sd(dev_employees)))
print(c("stddev company size (non-devs):", sd(non_dev_employees)))

# compare operating systems
arrange(as.data.frame(table(devs$sperating_system)), desc(Freq))
arrange(as.data.frame(table(non_devs$sperating_system)), desc(Freq))

# compare pageviews
head(pageviews_by_metric(dataset_pageviews, dataset_emails, 4), n = 4)

# compare active users in the last 30 days
combine_email_and_tenant_data(dataset_relation, dataset_emails, dataset_tenants, 4, 4)
```
* What are the most and least used technologies in tenants?
```{r}
library(stringr)

expand_commas <- function(dataset_, col_num){
    # save the column names for later
    old_email_name <- colnames(dataset_)[col_num]

    # rename the column for ease of reference
    colnames(dataset_)[col_num] <- "metric"

    # make column into vector and remove empty strings
    metric <- as.vector(dataset_$metric)
    metric <- metric[metric != ""]
    
    # get count of commas in elements and make a matrix to store the output
    comma_count <- sum(str_count(metric, ", "))
    metric_reduced <- matrix(NA , nrow=length(metric) + comma_count, ncol=1, dimnames=list(NULL, c("metric")))
    
    # for each value, if it has a comma, split it into a list and add each one to the matrix
    # if it doesn't have a comma, add it to the list
    index <- 1
    for (t in 1:length(metric)){
        if (grepl(", ", metric[t])){
            strings <- strsplit(metric[t], ", ")
            strings <- strings[[1]]
            for (s in 1:length(strings)){
                metric_reduced[index, 1] <- strings[s]
                index <- index + 1
            }
        } else {
            metric_reduced[index, 1] <- metric[t]
            index = index + 1
        }
    }
    
    # convert to a data frame and get a frequency count
    metric_reduced <- as.data.frame(metric_reduced)
    frequencies <- as.data.frame(lapply(metric_reduced, table))
    
    return(frequencies)
}
# dataset_tenants$technologies_used
result <- expand_commas(dataset_tenants, 9)

# display the bottom 5 and top 5
head(result[order(result$metric.Freq),], n = 5)
head(result[order(-result$metric.Freq),], n = 5)
```
* Please mark any inconsistencies you find in the data that you'd research further if you were working at Auth0
    + The column dataset_emails$sperating_system has a typo
    + The column dataset_tenants$technologies_used should be broken out into a seperate dataset.  Comma separated lists in data sets can get nasty.  The dataset would have two columns: "tenant_id" and "technology_used", where the latter column would be a single technology. If there are multiple techs used for one tenant, then there would be multiple rows. 
    + There is a similar problem for dataset_tenants$connection_types
    + There seem to be inconsistensies in columns with strings whether the default value is the empty string or NULL.  I would change these to default to NULL for ease of data analysis.
    + The column datatset_emails$login_method seems to have quite a few values that all start with hus_ followed by an aplha-numeric suffix.  Most of the values for these are fairly non-informative (None, Other, blank, NA).  These email_ids could be test data from auth0 itself. However, I would want to follow up and make sure that these aren't users that are trying to hide their tracks for nefarious purposes.

* Create at least 3 visualizations using R which you consider interesting for the provided data
```{r}

```
